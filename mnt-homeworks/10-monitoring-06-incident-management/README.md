# Домашнее задание к занятию "17.Инцидент-менеджмент"

## Задание 1

Составьте постмортем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

Ответ:
---

### Краткое описание инцидента

21 октября 2018 года, в 22:52 UTC сервис GitHub пострадал от нарушения связности сети и последующих проблем в работе БД. В результате пользователей наблюдали устаревшую или неполную информацию на сайте GitHub.com, а также на время восстановления была остановлена работа webhooks и Github Pages.

### Предшествующие события

Плановые работы по техническому обслуживанию для замены вышедшего из строя оптического оборудования.

### Причина инцидента

Неправильная настройка репликатора MySQL orchestrator. Потери связности на 43 секунды между датацентрами хватило, чтобы кластеры БД "развалились".

### Воздействие

В течение 24 часов и 11 минут 100% пользователей испытывали проблемы при работе с сайтом. Этот инцидент затронул отдельные части платформы, что привело к отображению устаревшей и неполной информации. В конечном счете, никакие пользовательские данные потеряны не были. GitHub также не мог обслуживать события webhook или создавать и публиковать GitHub Pages.

### Обнаружение

В 22:54 внутренние системы мониторинга начали генерировать предупреждения, указывающие на то, что
происходят многочисленные сбои. В 23:02 дежурные инженеры определили, что кластеры БД находяься в "неожиданном" состоянии. В 23:09 команда реагированя присвоила желтый статус проблеме, что перевело ситуацию в статус активного инцидента. Был проинформирован координатор инцидентов. 

### Реакция

Инцидент был устранен за 24 часа и 11 минут. Были привлечены дополнительные инженеры из команды администрирования БД.

### Восстановление

Был разработан план по восстановлению основного кластера на Восточном побережье США из резервной копии и последующей репликации актуальных данных с кластера на Западном побережье США. Отключенные внутренние сервисы - webhooks и Github Pages build. Когда нагрузка на сервис стала пиковой, были развёрнуты дополнительные read-only кластеры БД. Пойже были возвращены в работу отключенные сервисы, и скопившиеся в беклоге задачи по вызову webhooks и публикации GitHub Pages начали выполняться.

### Таймлайн

* 2018 October 21 22:52 UTC

```
Плановые работы по техническому обслуживанию для замены вышедшего из строя оптического оборудования
привели к потере связи между датацентрами. В следствии чего пострадал кластер БД. Связь между этими
пунктами была восстановлена за 43 секунды, но это хватило чтобы в двух частях кластера оказались 
новые уникальные данные.
```

* 2018 October 21 22:54 UTC

```
Внутренние системы мониторинга начали генерировать предупреждения, указывающие на то, что
происходят многочисленные сбои.
```

* 2018 October 21 23:02 UTC

```
Дежурные инженеры определили, что кластеры БД находились в "неожиданном" состоянии.
```

* 2018 October 21 23:07 UTC

```
Команда реагированя приняла решение заблокировать внетренние утилиты деплоя.
```

* 2018 October 21 23:09 UTC

```
Команда реагированя присвоила желтый статус проблеме, что перевело ситуацию в статус активного
инцидента. Был проинформирован координатор инцидентов. 
```

* 2018 October 21 23:13 UTC

```
Статус изменен на красный. Подключили дополнительных инженеров из команды администрирования БД.
```

* 2018 October 21 23:19 UTC

```
Остановлена работа webhook и сборку GitHub Pages чтобы не подвергать данные пользователей
дальнейшей опасности.
```

* 2018 October 22 00:05 UTC

```
Начали разработку плана по возврату кластера БД к консистентному состоянию.
```

* 2018 October 22 00:41 UTC

```
К этому времени был запущен процесс резервного восстановления для всех затронутых кластеров MySQL.
```

* 2018 October 22 06:51 UTC

```
Несколько кластеров завершили восстановление из резервных копий в датацентре на Восточном побережье
США и начали реплицировать новые данные с Западного побережья.
```

* 2018 October 22 07:46 UTC

```
GitHub опубликовал сообщение в блоге, чтобы предоставить больше информации. 
```

* 2018 October 22 11:12 UTC

```
Восстановился основной кластер БД на восточном побережье, что сделало систему гораздо более
отзывчивой. Но по прежнему оствались десятки read-only БД, которые продолжали репликацию, отставая
от мастера на несколько часов, по этой причине некоторые пользователей получали неконсистентные
данные. 
```

* 2018 October 22 13:15 UTC

```
Разрыв между мастером БД и репликами стал увеличиваться, вместо того чтобы сокращаться. Было
принято решения развернуть дополнительные реплики MySQL на чтение в датацентре Восточного побережья США.
```

* 2018 October 22 16:24 UTC

```
Реплики были синхронизированы, был выполнен переход на исходную топологию.
```

* 2018 October 22 16:45 UTC

```
Началась обработка отложенных событий. Было зарегистрировано более пяти миллионов событий webhook и
80 тысяч запросов на билд GitHub Pages. Был временно увеличен TTL для событий в очереди. 
```

* 2018 October 22 23:03 UTC

```
Все незавершенные сборки webhooks и Pages были обработаны, а целостность и надлежащее
функционирование всех систем были подтверждены. Статус сайта был изменен на зеленый.
```


### Последующие действия

* Во время восстановления были записаны журналы MySQL, содержащие записи, которые не были реплицированы на Западное побережье. Общее количество записей, которые не были реплицированы на Западное побережье, было относительно небольшим. Проводится анализ этих журналов и определяется, какие записи могут быть автоматически согласованы, а какие потребуют информирования пользователей. 
* Будут стремиться предоставлять более точную информацию во время инцидентов в будущем.
* Изменися конфигурация Orchestrator, чтобы предотвратить распространение primary роли через региональные границы. 
* Переход на новый механизм отчетности о статусе, который будет более информативным и будет оповещать о статусе отдельных компонентах сервиса.
* Началась работа по улучшению отказоустойчивости сервиса, чтобы система оставалась доступной даже при отказе одного из датацентров.
* Компания займет более активную позицию при проверке предположений о возможных сбоях.
* Начнется систематическая проверка сценариев сбоев. 